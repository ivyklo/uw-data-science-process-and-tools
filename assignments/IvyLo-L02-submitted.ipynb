{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "This is not a coding assignment, but for the sake of consistency we use this Jupyter notebook to work on it and submit it. For this assignment you will watch a video of a data science professional talking about a use case. Of course not every step will be easy to follow, but as data scientists we should be able to look at some complicated process in a and relate them to other common patterns we observe across use cases. So the goal of the assignment is to do this for one of the use cases listed below.\n",
    "\n",
    "You can choose any one of the following videos (you will need to be logged in as a student to access the videos):\n",
    "\n",
    "\n",
    "- DataKind: [Ethical data collection](https://learning.oreilly.com/videos/case-study-how/0636920672340/0636920672340-video338469/)\n",
    "- Pinterest: [Building a Stream Processing Platform](https://learning.oreilly.com/videos/case-study-how/0636920672371/0636920672371-video338013/)\n",
    "- Port of Montreal: [NLP for tracking cargo](https://learning.oreilly.com/videos/case-study-how/0636920623694/0636920623694-video336876/)\n",
    "- Kaiser Permanente: [Tracking pandemics](https://learning.oreilly.com/case-studies/analytics/how-kaiser-permanente-is-using/9781491991336-video325215/)\n",
    "- Northwestern: [Sports analytics](https://learning.oreilly.com/case-studies/analytics/how-major-league-baseball-team/9781491991336-video325217/)\n",
    "- Mount Sinai: [Risk models around population health](https://learning.oreilly.com/case-studies/analytics/how-mount-sinai-operationalize/9781491991336-video325210/)\n",
    "- Thomson Reuters: [Quantitative finance](https://learning.oreilly.com/case-studies/analytics/how-thomson-reuters-is-using-a/9781491991336-video325222/)\n",
    "- Wells Fargo: [Chatbots](https://learning.oreilly.com/case-studies/analytics/how-wells-fargo-uses-ai-and-na/9781491991336-video325226/)\n",
    "- Google: [User Experience](https://learning.oreilly.com/case-studies/analytics/how-google-is-using-ai-to-enha/9781491991336-video325272/)\n",
    "- Spotify: [User Experience](https://learning.oreilly.com/case-studies/machine-learning/how-spotify-uses-machine-learn/9781491991336-video325407/)\n",
    "- Uber: [Forecasting](https://learning.oreilly.com/case-studies/machine-learning/how-uber-uses-machine-learning/9781491991336-video325398/)\n",
    "- Zocdoc: [Healthcare marketplace](https://learning.oreilly.com/case-studies/machine-learning/how-zocdoc-uses-machine-learni/9781491991336-video318567/)\n",
    "- Pythian: [Predictive maintenance](https://learning.oreilly.com/videos/strata-data-conference/9781492050520/9781492050520-video324233)\n",
    "- Astro Digital: [Food economy](https://learning.oreilly.com/videos/strata-data-conference/9781492050520/9781492050520-video324321)\n",
    "- Airbnb: [Personalization](https://learning.oreilly.com/videos/strata-data-conference/9781492050520/9781492050520-video324238)\n",
    "\n",
    "Write a short report about the use case containing the following information:\n",
    "\n",
    "1. The business problems that the use case tries to solve. <span style=\"color:red\" float:right>[5 point]</span>\n",
    "2. What parts of the data science process were involved. <span style=\"color:red\" float:right>[5 point]</span>\n",
    "3. Challenges or questions faced during the steps of the data science process. <span style=\"color:red\" float:right>[10 point]</span>\n",
    "\n",
    "You can refer to the below diagram (also covered in class) for examples of questions that come up during the various steps of the data science process. As you watch the video, identify similar questions and their answers, and which steps of the data science process it relates to. Some use cases dive deep on one or two of these steps, and other use cases are more holistic. Note that this is not always clear-cut so do your best."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bg w:1200](./../images/data-science-process-big.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study Report\n",
    "\n",
    "## Case Study: NLP for tracking Cargo\n",
    "\n",
    "### The business problems that the use case tries to solve\n",
    "Port of Montreal wanted to address supply chain disruptions during the pandemic, particularly ensuring the timely delivery of critical cargo. Critical cargo could refer to essential goods and medical masks etc.  Since some essential items were missing from store shelves for months. The port needed a way to gain early visibility into shipments—often taking days or weeks to arrive—so they could plan logistics and prioritize critical items. The main challenge was to process unstructured text information about incoming cargo, extract relevant details, and determine whether shipments contained critical goods to help society maintain access to essential products.\n",
    "\n",
    "### What parts of the data science process were involved\n",
    "The project applied Natural Language Processing (NLP) and Machine Learning (ML) to analyze shipping data from the port of origin. The data science process included collecting and cleaning unstructured text data, structuring it through NLP, and building a classification model to predict whether a shipment was critical or not. The AI system also provided recommendations and advance visibility on expected arrival times, enabling better logistics preparation and provided a fast-track path for critical cargo. The team iterated on their model several times to refine accuracy.\n",
    "\n",
    "The data model in this case study roughly follows the CRISP-DM data flow process that involves business understanding (understanding the supply chain industry), data understanding (what kind of unstructured data are in the port's system), data preparation (building classifiers), modeling (using NLP and classifiers to classify critical cargo), evaluation and deployment (the data science team iterate the modesl a few times and incorprated customer feedback before final deployment). \n",
    "\n",
    "### Challenges or questions faced during the steps of the data science process\n",
    "\n",
    "The challenges of this case study can be summarized in these few points:\n",
    "\n",
    "- **Tight timeline:** Developing and implementing an AI solution within 12 weeks was highly demanding, but speaker noted that a shared goal helped drive focus and collaboration.\n",
    "\n",
    "- **Stakeholder understanding:** Educating non-technical stakeholders about AI and NLP concepts in simple terms was challenging, but worths the payoff for gaining buy-in and facilitating adoption.\n",
    "\n",
    "- **End-user involvement:** Engaging end-users early in the design process required multi-level communication between technical teams and operations, but it reduced risks and improved usability.\n",
    "\n",
    "- **Defining “good enough” performance:** It was a challenge to manage expectations, speaker recommended managing expectations about AI model accuracy using measurable metrics (e.g., 60%, 70%, or 80%) to align technical outcomes with business goals.\n",
    "\n",
    "- **Balancing automation and human input:** Determining the right mix between a fully automated system and a human-in-the-loop approach was a key challenge.\n",
    "\n",
    "- **Domain complexity:** Understanding the specialized language and logistics of the supply chain industry posed a significant learning curve for the data science team."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of assignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
